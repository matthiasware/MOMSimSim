{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet50\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from model import SimSiam\n",
    "from utils import AverageMeter, get_dataset, get_backbone, get_optimizer, get_scheduler\n",
    "from augmentations import get_aug\n",
    "from dotted_dict import DottedDict\n",
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- tensorboard\n",
    "- multi gpu training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "timestamp = \"tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DottedDict()\n",
    "config.p_data = Path(\"/usr/data/pytorch\")\n",
    "config.p_train = Path(\"/usr/experiments/simsiam\") / \"run_{}\".format(timestamp)\n",
    "config.p_ckpts = config.p_train / \"ckpts\"\n",
    "config.p_logs = config.p_train / \"logs\"\n",
    "config.fs_ckpt = \"model_{}_epoch_{:0>6}.ckpt\"\n",
    "config.mean_std = [[0.485, 0.456, 0.406],[0.229, 0.224, 0.225]]\n",
    "config.dataset = \"cifar10\"\n",
    "config.backbone = \"resnet18\"\n",
    "config.batch_size = 512\n",
    "config.num_epochs = 800\n",
    "config.img_size = 32\n",
    "config.optimizer = \"sgd\"\n",
    "config.optimizer_args = {\n",
    "     \"lr\": 0.03,\n",
    "     \"weight_decay\": 0.0005,\n",
    "     \"momentum\": 0.9\n",
    "}\n",
    "config.scheduler = \"cosine_decay\"\n",
    "config.scheduler_args = {\n",
    "    \"T_max\": 800,\n",
    "    \"eta_min\": 0,\n",
    "}\n",
    "config.debug = False\n",
    "config.num_workers = 8\n",
    "config.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "config.resume = False\n",
    "#\n",
    "# debug settings\n",
    "if config.debug:\n",
    "    config.batch_size = 2 \n",
    "    config.num_epochs = 5 # train only one epoch\n",
    "    config.num_workers = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = get_aug(img_size=config.img_size,\n",
    "                    train=True,\n",
    "                    train_classifier=False,\n",
    "                    means_std=config.mean_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = get_dataset(config.dataset, config.p_data, transform=transform)\n",
    "if config.debug:\n",
    "    train_set = torch.utils.data.Subset(train_set, range(0, config.batch_size)) # take only one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_set,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = get_backbone(config.backbone)\n",
    "model = SimSiam(backbone).to(config.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = get_optimizer(config.optimizer, model, config.optimizer_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lr scheduler\n",
    "lr_scheduler = get_scheduler(config.scheduler, optimizer, config.scheduler_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_meter = AverageMeter(\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create train dir\n",
    "config.p_logs.mkdir(exist_ok=True, parents=True)\n",
    "config.p_ckpts.mkdir(exist_ok=True, parents=True)\n",
    "#\n",
    "# tensorboard writer\n",
    "writer = SummaryWriter(config.p_logs)\n",
    "print(\"tensorboard --logdir={} --host=0.0.0.0\".format(str(config.p_logs)))\n",
    "#\n",
    "for epoch in tqdm(range(1, config.num_epochs+1), desc=f'Training'):\n",
    "    loss_meter.reset()\n",
    "    model.train()\n",
    "    p_bar=tqdm(train_loader, desc=f'Epoch {epoch}/{config.num_epochs}')\n",
    "    for idx, ((images1, images2), labels) in enumerate(p_bar):\n",
    "        model.zero_grad()\n",
    "        loss = model.forward(images1.to(config.device), images2.to(config.device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_meter.update(loss.item())\n",
    "        p_bar.set_postfix({\"loss\":loss_meter.val, 'loss_avg':loss_meter.avg})\n",
    "        lr_scheduler.step()\n",
    "        writer.add_scalar('loss', loss_meter.val, epoch * len(train_loader) + idx)\n",
    "        writer.add_scalar('avg_loss', loss_meter.avg, epoch * len(train_loader) + idx)\n",
    "    \n",
    "    # Save checkpoint\n",
    "    p_ckpt = config.p_ckpts / config.fs_ckpt.format(config.dataset, epoch)\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'state_dict':model.state_dict(),\n",
    "        # 'optimizer':optimizer.state_dict(), # will double the checkpoint file size\n",
    "        'lr_scheduler':lr_scheduler.state_dict(),\n",
    "        'config': config,\n",
    "        'loss_meter':loss_meter\n",
    "        }, p_ckpt)\n",
    "    print(f\"Model saved to {p_ckpt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_1 = torch.rand(4, 3, config.img_size, img_size).to(config.device)\n",
    "X_test_2 = torch.rand(X_test_1.shape).to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "L_test_1 = model.forward(X_test_1, X_test_2)\n",
    "#\n",
    "model = SimSiam(resnet50()).to(device)\n",
    "#\n",
    "p_model = fs_p_model.format(dataset, num_epochs)\n",
    "model.load_state_dict(torch.load(p_model)[\"state_dict\"])\n",
    "model = model.eval()\n",
    "#\n",
    "L_test_2 = model.forward(X_test_1, X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_test_1 - L_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_test_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# delete stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /usr/experiments/simsiam/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
