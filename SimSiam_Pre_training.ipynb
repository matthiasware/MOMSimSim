{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sayakpaul/SimSiam-TF/blob/main/SimSiam_Pre_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3OQSgi4A8qI"
   },
   "source": [
    "A minimal implementation of **SimSiam** as proposed in [Exploring Simple Siamese Representation Learning](https://arxiv.org/pdf/2011.10566.pdf) by Xinlei Chen and Kaiming He. The objective of this notebook is to demonstrate the workflow of SimSiam and NOT to implement it note to note and at the same time I will try not to miss out on the major bits discussed in the paper. For that matter, I'll be using the Flowers dataset. \n",
    "\n",
    "Following depicts the workflow of SimSiam - \n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.ibb.co/37pNQTP/image.png\" width=550></img>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KqSmdKq1DXdw",
    "outputId": "ce07b623-0cb2-4d5d-ee7d-997325cc1f4a"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__OnMx5CA4OB"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HcAlVdqoB1Ik"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tf.random.set_seed(666)\n",
    "np.random.seed(666)\n",
    "\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fWNjwy4aB0S4",
    "outputId": "342595e2-a41e-4eb7-950b-5bbcf20aa16b"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxDHbKMxCgq5",
    "outputId": "ade152a1-544e-4093-9ba3-2866a2cffa7e"
   },
   "outputs": [],
   "source": [
    "# Gather Flowers dataset\n",
    "train_ds, validation_ds = tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    split=[\"train[:85%]\", \"train[85%:]\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "id": "uydnjpuNCg7K",
    "outputId": "7ec49b70-4b26-4f72-a3ca-dd9d3958e670"
   },
   "outputs": [],
   "source": [
    "# Visualization\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, image  in enumerate(train_ds.take(9)):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image['image'])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnhfS83AC6g8"
   },
   "source": [
    "Note the augmentation pipeline is a bit different from the augmentations followed in the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1og_oen5Cjm6"
   },
   "outputs": [],
   "source": [
    "# Reference: https://github.com/google-research/simclr/blob/master/data_util.py\n",
    "\n",
    "@tf.function\n",
    "def translate(image):\n",
    "    (h, w) = tf.shape(image)[0], tf.shape(image)[1]\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    f = tf.random.uniform([], minval=0, maxval=0.125, dtype=tf.float32)\n",
    "    (dh, dw) = tf.cast(tf.cast(h, tf.float32)*f, tf.float32), \\\n",
    "        tf.cast(tf.cast(w, tf.float32)*f, tf.float32)\n",
    "    \n",
    "    image = tfa.image.translate(image, translations=[dh, dw])\n",
    "    return image\n",
    "\n",
    "@tf.function\n",
    "def gaussian_blur(image, kernel_size=23, padding='SAME'):\n",
    "    sigma = tf.random.uniform((1,))* 1.9 + 0.1\n",
    "\n",
    "    radius = tf.cast(kernel_size / 2, tf.int32)\n",
    "    kernel_size = radius * 2 + 1\n",
    "    x = tf.cast(tf.range(-radius, radius + 1), tf.float32)\n",
    "    blur_filter = tf.exp(\n",
    "        -tf.pow(x, 2.0) / (2.0 * tf.pow(tf.cast(sigma, tf.float32), 2.0)))\n",
    "    blur_filter /= tf.reduce_sum(blur_filter)\n",
    "    # One vertical and one horizontal filter.\n",
    "    blur_v = tf.reshape(blur_filter, [kernel_size, 1, 1, 1])\n",
    "    blur_h = tf.reshape(blur_filter, [1, kernel_size, 1, 1])\n",
    "    num_channels = tf.shape(image)[-1]\n",
    "    blur_h = tf.tile(blur_h, [1, 1, num_channels, 1])\n",
    "    blur_v = tf.tile(blur_v, [1, 1, num_channels, 1])\n",
    "    expand_batch_dim = image.shape.ndims == 3\n",
    "    if expand_batch_dim:\n",
    "        image = tf.expand_dims(image, axis=0)\n",
    "    blurred = tf.nn.depthwise_conv2d(\n",
    "        image, blur_h, strides=[1, 1, 1, 1], padding=padding)\n",
    "    blurred = tf.nn.depthwise_conv2d(\n",
    "        blurred, blur_v, strides=[1, 1, 1, 1], padding=padding)\n",
    "    if expand_batch_dim:\n",
    "        blurred = tf.squeeze(blurred, axis=0)\n",
    "    return blurred\n",
    "\n",
    "@tf.function\n",
    "def color_jitter(x, s=0.5):\n",
    "    x = tf.image.random_brightness(x, max_delta=0.8*s)\n",
    "    x = tf.image.random_contrast(x, lower=1-0.8*s, upper=1+0.8*s)\n",
    "    x = tf.image.random_saturation(x, lower=1-0.8*s, upper=1+0.8*s)\n",
    "    x = tf.image.random_hue(x, max_delta=0.2*s)\n",
    "    x = tf.clip_by_value(x, 0, 1)\n",
    "    return x\n",
    "\n",
    "@tf.function\n",
    "def color_drop(x):\n",
    "    x = tf.image.rgb_to_grayscale(x)\n",
    "    x = tf.tile(x, [1, 1, 3])\n",
    "    return x\n",
    "\n",
    "@tf.function\n",
    "def random_apply(func, x, p):\n",
    "    return tf.cond(\n",
    "        tf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
    "                tf.cast(p, tf.float32)),\n",
    "        lambda: func(x),\n",
    "        lambda: x)\n",
    "\n",
    "@tf.function\n",
    "def custom_augment(image):\n",
    "    image = image['image']\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "\n",
    "    # Random flips\n",
    "    image = random_apply(tf.image.flip_left_right, image, p=0.5)\n",
    "    # Random translations\n",
    "    image = random_apply(translate, image, p=0.5)\n",
    "    # Randomly apply gausian blur\n",
    "    image = random_apply(gaussian_blur, image, p=0.5)\n",
    "    # Randomly apply transformation (color distortions) \n",
    "    image = random_apply(color_jitter, image, p=0.8)\n",
    "    # Randomly apply grayscale\n",
    "    image = random_apply(color_drop, image, p=0.2)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Amu7k8OvD1br"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "dataset_one = (\n",
    "    train_ds\n",
    "    .shuffle(1024)\n",
    "    .map(custom_augment, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "dataset_two = (\n",
    "    train_ds\n",
    "    .shuffle(1024)\n",
    "    .map(custom_augment, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "id": "0GA60Ky9EmXu",
    "outputId": "a6910fcd-9e78-49e3-b5df-2b779859e93f"
   },
   "outputs": [],
   "source": [
    "sample_images = next(iter(dataset_one))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for n in range(25):\n",
    "    ax = plt.subplot(5, 5, n+1)\n",
    "    plt.imshow(sample_images[n])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WM69XILOTRJ9"
   },
   "source": [
    "The network architectures are based on the **Method (Baseline settings)** section of the paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPoeLlhwFyTh"
   },
   "source": [
    "## Encoder ($f$)\n",
    "\n",
    "This includes ResNet50 as a backbone and another MLP for projection. Note that I have reduced the architectures here leaving ResNet50 backbone intact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EUx5xZxKFJ-a"
   },
   "outputs": [],
   "source": [
    "def get_encoder():\n",
    "    base_model = tf.keras.applications.ResNet50(include_top=False,\n",
    "        weights=None, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = True\n",
    "\n",
    "    inputs = tf.keras.layers.Input((224, 224, 3))\n",
    "    x = base_model(inputs, training=True)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(2048, activation='relu', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    z = tf.keras.layers.Dense(2048)(x)\n",
    "\n",
    "    f = tf.keras.Model(inputs, z)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRvzAOIBSjoG"
   },
   "source": [
    "## Predictor ($h$)\n",
    "\n",
    "This includes an MLP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qtcNe7znSjCH"
   },
   "outputs": [],
   "source": [
    "def get_predictor():\n",
    "    inputs = tf.keras.layers.Input((2048, ))\n",
    "    x = tf.keras.layers.Dense(512, activation='relu', use_bias=False)(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    p = tf.keras.layers.Dense(2048)(x)\n",
    "\n",
    "    h = tf.keras.Model(inputs, p)\n",
    "\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4n5xwsFWJl7e",
    "outputId": "16328095-ca65-49c4-b1b1-c490181bea36"
   },
   "outputs": [],
   "source": [
    "get_encoder().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w2mcoe9JJror",
    "outputId": "1a3ec7a6-88df-4d18-8f96-d628695f53e4"
   },
   "outputs": [],
   "source": [
    "get_predictor().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7gjLDPmKPNn"
   },
   "source": [
    "The authors have also provided PyTorch-like psuedocode in the paper (how cool!) - \n",
    "\n",
    "```python\n",
    "# f: backbone + projection mlp\n",
    "# h: prediction mlp\n",
    "for x in loader: # load a minibatch x with n samples\n",
    "    x1, x2 = aug(x), aug(x) # random augmentation\n",
    "    z1, z2 = f(x1), f(x2) # projections, n-by-d\n",
    "    p1, p2 = h(z1), h(z2) # predictions, n-by-d\n",
    "    L = D(p1, z2)/2 + D(p2, z1)/2 # loss\n",
    "    L.backward() # back-propagate\n",
    "    update(f, h) # SGD update\n",
    "\n",
    "def D(p, z): # negative cosine similarity\n",
    "    z = z.detach() # stop gradient\n",
    "    p = normalize(p, dim=1) # l2-normalize\n",
    "    z = normalize(z, dim=1) # l2-normalize\n",
    "    return -(p*z).sum(dim=1).mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mU8zs96EJ3Bc"
   },
   "outputs": [],
   "source": [
    "def loss_func(p, z):\n",
    "    z = tf.stop_gradient(z)\n",
    "    p = tf.math.l2_normalize(p, axis=1)\n",
    "    z = tf.math.l2_normalize(z, axis=1)\n",
    "    return - tf.reduce_mean(tf.reduce_sum((p*z), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P4-yuvuZMT0n"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(ds_one, ds_two, f, h, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        z1, z2 = f(ds_one), f(ds_two)\n",
    "        p1, p2 = h(z1), h(z2)\n",
    "        loss = loss_func(p1, z2)/2 + loss_func(p2, z1)/2\n",
    "    \n",
    "    learnable_params = f.trainable_variables + h.trainable_variables\n",
    "    gradients = tape.gradient(loss, learnable_params)\n",
    "    optimizer.apply_gradients(zip(gradients, learnable_params))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3jIbS4R4O8kY"
   },
   "outputs": [],
   "source": [
    "def train_simsiam(f, h, dataset_one, dataset_two, optimizer, epochs=100):\n",
    "    step_wise_loss = []\n",
    "    epoch_wise_loss = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for ds_one, ds_two in zip(dataset_one, dataset_two):\n",
    "            loss = train_step(ds_one, ds_two, f, h, optimizer)\n",
    "            step_wise_loss.append(loss)\n",
    "\n",
    "        epoch_wise_loss.append(np.mean(step_wise_loss))\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"epoch: {} loss: {:.3f}\".format(epoch + 1, np.mean(step_wise_loss)))\n",
    "\n",
    "    return epoch_wise_loss, f, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ys3VkUqVP_3r",
    "outputId": "b6393ae7-09d5-4872-ed1e-53721353ab8f"
   },
   "outputs": [],
   "source": [
    "decay_steps = 500\n",
    "lr_decayed_fn = tf.keras.experimental.CosineDecay(\n",
    "    initial_learning_rate=0.01, decay_steps=decay_steps)\n",
    "optimizer = tf.keras.optimizers.SGD(lr_decayed_fn, momentum=0.6)\n",
    "\n",
    "f = get_encoder()\n",
    "h = get_predictor()\n",
    "\n",
    "epoch_wise_loss, f, h  = train_simsiam(f, h, dataset_one, dataset_two, optimizer, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kiJx3y5EQ57_"
   },
   "outputs": [],
   "source": [
    "plt.plot(epoch_wise_loss)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.save_weights(\"projection.h5\")\n",
    "h.save_weights(\"prediction.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNhEd2EnuPKQjsGMvm+zE3l",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "SimSiam_Pre-training.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
