{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.7445)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from model import D\n",
    "size = (1, 32, 64)\n",
    "p = torch.rand(size)\n",
    "z = torch.rand(size)\n",
    "D(p, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROJECTION MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import projection_MLP\n",
    "#\n",
    "d_i = 256\n",
    "d_h = 1024\n",
    "d_o = 1024\n",
    "n_hidden = 10\n",
    "b = 4\n",
    "#\n",
    "# in = [b, d_i, 1, 1]\n",
    "f = projection_MLP(d_i, d_h, d_o, n_hidden)\n",
    "#\n",
    "x = torch.rand(b, d_i, 1, 1)\n",
    "y = f(x)\n",
    "#\n",
    "assert y.shape == torch.Size((b, d_o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICTION MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import prediction_MLP\n",
    "#\n",
    "d_i = 2048\n",
    "d_h = 512\n",
    "d_o = 2048\n",
    "b = 8\n",
    "#\n",
    "f = prediction_MLP(d_i, d_h, d_o)\n",
    "#\n",
    "x = torch.rand(b, d_i)\n",
    "#\n",
    "y = f(x)\n",
    "#\n",
    "assert y.shape == torch.Size((b, d_o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SimSiam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import SimSiam\n",
    "from torchvision.models import resnet50\n",
    "#\n",
    "b = 8\n",
    "channels = 3\n",
    "img_size = 224\n",
    "projector_args = {\n",
    "    \"hidden_dim\": 2048,\n",
    "    \"out_dim\": 2048,\n",
    "    \"n_hidden_layers\": 1\n",
    "}\n",
    "predictor_args = {\n",
    "    \"hidden_dim\": 512,\n",
    "    \"in_dim\":  projector_args[\"out_dim\"],\n",
    "    \"out_dim\": projector_args[\"out_dim\"]\n",
    "}\n",
    "#\n",
    "x1 = torch.rand(b, channels, img_size, img_size)\n",
    "x2 = torch.rand(x1.size())\n",
    "#\n",
    "backbone = resnet50()\n",
    "#\n",
    "model = SimSiam(backbone, projector_args, predictor_args)\n",
    "L = model(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'backbone': 'resnet50',\n",
      "  'base_lr': 0.05,\n",
      "  'batch_size': 512,\n",
      "  'dataset': 'imagenet',\n",
      "  'debug': False,\n",
      "  'device': 'cuda:0',\n",
      "  'fs_ckpt': 'model_{}_epoch_{:0>6}.ckpt',\n",
      "  'img_size': 224,\n",
      "  'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]],\n",
      "  'num_epochs': 100,\n",
      "  'num_workers': 8,\n",
      "  'optimizer': 'sgd',\n",
      "  'optimizer_args': {'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0001},\n",
      "  'p_ckpts': PosixPath('/usr/experiments/simsiam/run_imagenet_resnet50_20201203-124522/ckpts'),\n",
      "  'p_data': PosixPath('/usr/data/pytorch'),\n",
      "  'p_logs': PosixPath('/usr/experiments/simsiam/run_imagenet_resnet50_20201203-124522/logs'),\n",
      "  'p_train': PosixPath('/usr/experiments/simsiam/run_imagenet_resnet50_20201203-124522'),\n",
      "  'predictor_args': {'hidden_dim': 512, 'in_dim': 2048, 'out_dim': 2048},\n",
      "  'projector_args': {'hidden_dim': 2048, 'n_hidden_layers': 1, 'out_dim': 2048},\n",
      "  'resume': False,\n",
      "  'scheduler': 'cosine_decay',\n",
      "  'scheduler_args': {'T_max': 800, 'eta_min': 0}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "from configs import *\n",
    "#\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "#\n",
    "config = simsiam_default(debug=False)\n",
    "config = add_paths(config)\n",
    "pp.pprint(config)\n",
    "#\n",
    "config = simsiam_cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'backbone': 'resenet18',\n",
      "  'base_lr': 0.03,\n",
      "  'batch_size': 512,\n",
      "  'dataset': 'cifar10',\n",
      "  'debug': False,\n",
      "  'device': 'cuda:0',\n",
      "  'fs_ckpt': 'model_{}_epoch_{:0>6}.ckpt',\n",
      "  'img_size': 32,\n",
      "  'mean_std': [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]],\n",
      "  'num_epochs': 100,\n",
      "  'num_workers': 8,\n",
      "  'optimizer': 'sgd',\n",
      "  'optimizer_args': {'lr': 0.06, 'momentum': 0.9, 'weight_decay': 0.0005},\n",
      "  'predictor_args': {'hidden_dim': 512, 'in_dim': 2048, 'out_dim': 2048},\n",
      "  'projector_args': {'hidden_dim': 2048, 'n_hidden_layers': 0, 'out_dim': 2048},\n",
      "  'resume': False,\n",
      "  'scheduler': 'cosine_decay',\n",
      "  'scheduler_args': {'T_max': 800, 'eta_min': 0}}\n"
     ]
    }
   ],
   "source": [
    "config = simsiam_cifar10()\n",
    "pp.pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Augementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from augmentations import SimSiamAugmentations, LinearProbAugmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mean_std = [[0.485, 0.456, 0.406],[0.229, 0.224, 0.225]]\n",
    "img_size = 60\n",
    "x = PIL.Image.open(\"data/flower.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SimSiam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_do_norm = SimSiamAugmentations(img_size, imagenet_mean_std)\n",
    "aug_no_norm = SimSiamAugmentations(img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2 = aug_do_norm(x)\n",
    "#\n",
    "x1 = x1.transpose(0, 2).numpy()\n",
    "x2 = x2.transpose(0, 2).numpy()\n",
    "#\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 5))\n",
    "axs[0].imshow(np.array(x))\n",
    "axs[1].imshow(x1)\n",
    "axs[2].imshow(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2 = aug_no_norm(x)\n",
    "#\n",
    "x1 = x1.transpose(0, 2).numpy()\n",
    "x2 = x2.transpose(0, 2).numpy()\n",
    "#\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 5))\n",
    "axs[0].imshow(np.array(x))\n",
    "axs[1].imshow(x1)\n",
    "axs[2].imshow(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_train = LinearProbAugmentations(img_size, train=True)\n",
    "aug_valid = LinearProbAugmentations(img_size, train=False)\n",
    "#\n",
    "x_aug_train = aug_train(x).transpose(0, 2).numpy()\n",
    "x_aug_valid = aug_valid(x).transpose(0, 2).numpy()\n",
    "#\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 5))\n",
    "axs[0].imshow(np.array(x))\n",
    "axs[1].imshow(x_aug_train)\n",
    "axs[2].imshow(x_aug_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_train = LinearProbAugmentations(img_size, train=True, means_std=imagenet_mean_std)\n",
    "aug_valid = LinearProbAugmentations(img_size, train=False, means_std=imagenet_mean_std)\n",
    "#\n",
    "x_aug_train = aug_train(x).transpose(0, 2).numpy()\n",
    "x_aug_valid = aug_valid(x).transpose(0, 2).numpy()\n",
    "#\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 5))\n",
    "axs[0].imshow(np.array(x))\n",
    "axs[1].imshow(x_aug_train)\n",
    "axs[2].imshow(x_aug_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from augmentations import get_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_aug(64, train=True, train_classifier=False))\n",
    "print(get_aug(64, train=True, train_classifier=True))\n",
    "print(get_aug(64, train=False, train_classifier=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backbones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_backbone(\"vgg16\")\n",
    "model = get_backbone(\"resnet50\")\n",
    "model = get_backbone(\"resnet18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_optimizer\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.mobilenet_v2()\n",
    "optimizer_args = {\n",
    "     \"lr\": 0.03,\n",
    "     \"weight_decay\": 0.0005,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = get_optimizer(\"sgd\", model, optimizer_args)\n",
    "print(optim)\n",
    "optim = get_optimizer(\"adam\", model, optimizer_args)\n",
    "print(optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler_name = \"cosine_decay\"\n",
    "scheduler_args = {\"T_max\": 100, \"eta_min\":0}\n",
    "\n",
    "scheduler = get_scheduler(scheduler_name, optim, scheduler_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_dataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "img_size = 96\n",
    "p_data = \"/mnt/data/pytorch\"\n",
    "dataset = \"cifar10\"\n",
    "ds_train = get_dataset(\n",
    "                 dataset=dataset,\n",
    "                 data_dir=p_data,\n",
    "                 transform=None,\n",
    "                 train=True,\n",
    "                 download=False)\n",
    "\n",
    "ds_test = get_dataset(\n",
    "                 dataset=dataset,\n",
    "                 data_dir=p_data,\n",
    "                 transform=None,\n",
    "                 train=False,\n",
    "                 download=False)\n",
    "#\n",
    "print(len(ds_train))\n",
    "print(len(ds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(np.array(ds_train[0][0]))\n",
    "ax[1].imshow(np.array(ds_test[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = torchvision.datasets.CIFAR100(p_data, train=True, transform=None, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
