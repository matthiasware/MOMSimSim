{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from augmentations import get_aug\n",
    "from utils import get_dataset\n",
    "from torchvision.models import resnet50\n",
    "from model import SimSiam\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from utils import AverageMeter\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "#\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "#\n",
    "from dotted_dict import DottedDict\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "#\n",
    "from utils import AverageMeter, get_dataset, get_backbone, get_optimizer, get_scheduler\n",
    "from augmentations import get_aug\n",
    "from model import SimSiam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ckpt = Path(\n",
    "    \"/usr/experiments/simsiam/run_20201202-201102/ckpts/model_cifar10_epoch_000012.ckpt\")\n",
    "assert p_ckpt.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(p_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = ckpt[\"config\"]\n",
    "pp.pprint(train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DottedDict()\n",
    "config.device = 'cuda:1'\n",
    "config.optimizer = 'sgd'\n",
    "config.optimizer_args = {\n",
    "    'lr': 30,\n",
    "    'weight_decay': 0,\n",
    "    'momentum': 0.9\n",
    "}\n",
    "config.batch_size = 256\n",
    "config.img_size = train_config.img_size\n",
    "config.debug = False\n",
    "config.num_workers = 8\n",
    "config.num_epochs = 800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = get_dataset(\n",
    "        train_config.dataset, \n",
    "        train_config.p_data, \n",
    "        transform=get_aug(config.img_size, train=True, train_classifier=True), \n",
    "        train=True, \n",
    "        download=False\n",
    "    )\n",
    "test_set = get_dataset(\n",
    "        train_config.dataset, \n",
    "        train_config.p_data, \n",
    "        transform=get_aug(config.img_size, train=True, train_classifier=True),\n",
    "        train=False, \n",
    "        download=True # default is False\n",
    "    )\n",
    "if config.debug:\n",
    "    train_set = torch.utils.data.Subset(train_set, range(0, config.batch_size)) # take only one batch\n",
    "    test_set = torch.utils.data.Subset(test_set, range(0, config.batch_size))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_set,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_set,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load backbone\n",
    "backbone = get_backbone(train_config[\"backbone\"])\n",
    "in_features = backbone.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone.fc = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = {k[9:]:v for k, v in ckpt['state_dict'].items() if k.startswith('backbone.')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nn.Linear(in_features=in_features, out_features=len(train_set.classes), bias=True)\n",
    "classifier = classifier.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = get_optimizer(config.optimizer, classifier, config.optimizer_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_meter = AverageMeter(name='Loss')\n",
    "acc_meter = AverageMeter(name='Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, config.num_epochs + 1):\n",
    "    #\n",
    "    # TRAIN LOOP\n",
    "    #\n",
    "    loss_meter.reset()\n",
    "    model.eval()\n",
    "    classifier.train()\n",
    "    p_bar=tqdm(train_loader, desc=f'Epoch {epoch}/{config.num_epochs}', position=1)\n",
    "    for idx, (images, labels) in enumerate(p_bar):\n",
    "        classifier.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            feature = model(images.to(config.device))\n",
    "        preds = classifier(feature)\n",
    "        #\n",
    "        loss = F.cross_entropy(preds, labels.to(config.device))\n",
    "        optimizer.step()\n",
    "        loss_meter.update(loss.item())\n",
    "        p_bar.set_postfix({\"loss\":loss_meter.val, 'loss_avg':loss_meter.avg})\n",
    "    #\n",
    "    # EVAL LOOP\n",
    "    #\n",
    "    classifier.eval()\n",
    "    correct, total = 0, 0\n",
    "    acc_meter.reset()\n",
    "    p_bar=tqdm(test_loader, desc=f'Test {epoch}/{config.num_epochs}')\n",
    "    for idx, (images, labels) in enumerate(p_bar):\n",
    "        with torch.no_grad():\n",
    "            feature = model(images.to(config.device))\n",
    "            preds = classifier(feature).argmax(dim=1)\n",
    "            correct = (preds == labels.to(config.device)).sum().item()\n",
    "            acc_meter.update(correct/preds.shape[0])\n",
    "            p_bar.set_postfix({'accuracy': acc_meter.avg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
